<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>OS学习_内存管理</title>
      <link href="2021/07/16/OS%E5%AD%A6%E4%B9%A0-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>2021/07/16/OS%E5%AD%A6%E4%B9%A0-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>前面有提到过, 操作系统要完成多个进程中的隔离, 想要使得两个程序达成隔离, 从内存方面就必须达成隔离, 程序A不能访问到程序B所属的内存, 才是我们想要的隔离.</p><p>在我们学习编写程序时, 时常能够看到一些地址及其操作. 例如像<code>0x12345678</code>这样的地址. 在计算机中, 从程序员的角度来看, 我们能够通过某个地址访问到我们程序中的数据或代码. 按照正常的物理分配, 程序加载到内存中应该是这样的:</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210727165451393.png" alt="物理内存"></p><p>无疑这样设置内存结构是不安全的, 但是真实的物理内存中就是这样的结构.</p><p>假设我是程序B, 我知道自己的地址空间位于<code>0x8000</code>到<code>0x9000</code>之间, 依次类推, 我就猜测<code>0xA000</code>到<code>0xB000</code>也有一个程序, 这样完全起不到隔离的作用. 我可以将一个脏数据写到别的程序那去.</p><p>然后就可能会有想到这样的实现, 在程序访问内存时做有效性校验,判断程序读写的区域是否属于自身. 实现上这样确实会避免许多不安全操作, 但是在每次读写操作前校验安全性给CPU带来很大的性能开销, 另外也可能在内存中有前一个应用留下来的脏数据影响程序运行.</p><p>于是, 计算机科学家们提出了虚拟地址的概念. 不仅让每个程序拥有了一个完整的空间, 使得整个程序可以在自身的虚拟空间内随意操作, 更是完成了进程间的内存空间隔离.</p><p>操作系统将物理地址映射到虚拟地址上, 由进程操作虚拟地址, 操作系统就可以对对应的物理地址操作. 各个进程间是没办法相互访问到了, 因为大家都有<code>0x0000</code>, 而这些<code>0x0000</code> 实际上对应的是不同位置的物理内存, 于是现在内存就变成了这样:</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/20210729095730.png" alt="虚拟地址映射"></p><h2 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h2><p>于是在我们使用程序时, 就存在两种不同叫法的地址空间 (实际上是相同的位置).</p><ul><li>程序所读写的内存地址叫做<strong>虚拟内存地址</strong>.</li><li>操作系统实际读写的内存地址叫做<strong>物理内存地址</strong>.</li></ul><p>每个进程在初始化的时候, 操作系统会分配出一块地址空间给进程, 当进程访问虚拟地址时, CPU会通过MMU(内存管理模块) 将虚拟地址转换为物理地址, 再使用物理地址访问内存.</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/20210729104356.png" alt="MMU地址转换"></p><p>实际上操作系统对内存的管理是更加细粒化的, 我们不难发现, 假设我们电脑有4G的内存, 映射出来最底下的空间应该为<code>0x00000000</code>, 一共有32个二进制位代表的地址. 如果我们想要从$2^{32}$个地址中直接寻找一个地址, 无疑开销是非常大的.</p><p>因此产生了<strong>内存分段</strong>和<strong>内存分页</strong>两种内存管理方式, 我认为其中的基本思想是分层映射.</p><h2 id="内存分段"><a href="#内存分段" class="headerlink" title="内存分段"></a>内存分段</h2><p> 程序在编译时分为代码分段, 数据分段, 栈段和堆段. 不同的段需要有不同的读写执行属性, </p><h2 id="页式硬件"><a href="#页式硬件" class="headerlink" title="页式硬件"></a>页式硬件</h2><p>页表</p><p>内存管理单元 : 虚拟地址转换物理地址</p><p>内存管理单元 -&gt; 页表</p><p>CPU寄存器<code>satp</code> -&gt; 页表 -&gt; 内存</p><p>硬件采取多级树实现页表</p>]]></content>
      
      
      <categories>
          
          <category> 计算机 </category>
          
          <category> 学习 </category>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OS学习_系统结构及系统调用</title>
      <link href="2021/07/09/OS%E5%AD%A6%E4%B9%A0-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E5%8F%8A%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"/>
      <url>2021/07/09/OS%E5%AD%A6%E4%B9%A0-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E5%8F%8A%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h1><p>根据之前提到的操作系统索要达成的目标, 可以得出操作系统是为什么要存在.</p><p>无外乎有几点.</p><ol><li>对底层硬件的抽象, 对于大部分开发来说, 硬件的东西总是比较困难的, 想办法讲硬件抽象成简单的接口更有利于开发应用.</li><li>对各应用程序之间产生隔离. 应用直接对底层硬件操作, 难免会对一些资源有所争抢, 甚至是通过底层硬件进入其他应用.</li><li>应用之间的隔离又不能完全隔离. 人和人之间要沟通, 应用之间也难免要发生信息交换. 于是乎隔离和交互间又存在安全问题.</li></ol><h2 id="硬件抽象"><a href="#硬件抽象" class="headerlink" title="硬件抽象"></a>硬件抽象</h2><p>对于大部分人来说, 开发应用的时候能多方便就多方便, 但是想要获取更高的性能, 只能向底层硬件贴近. 对于大佬来说, 自己动手造轮子, 与硬件交互的代码自己编写成库, 无疑能够让程序获得高性能. </p><p>事实上也是有这样的实现, 例如在嵌入式OS的开发中或是在实时系统(RTOS)中开发. 无外乎这些系统的目标都需要高性能, 并且目标单一.在这种情况下, 开发人员也许会选择让应用程序操作硬件资源.</p><p>在平时我们使用的操作系统中, 无论是Windows或是Linux系下的系统, 设计目的并不是为了单一的某个应用, 在用户进行某项应用的操作时, 背后往往会运行着其支撑服务或是其他应用. 例如我现在在写文章, 使用的编辑器, 其背后还会有Markdown的实时渲染引擎在运作, 而渲染引擎又可能依赖别的基础服务. 当所有的应用都希望获得高性能, 所有的应用都会争抢这一份硬件资源来给自身提高战力. 这时便需要有一个人来维持这么多应用之间的”秩序”, 而操作系统就是那个领导者.</p><p>除了对底层硬件资源的争夺, 更需要担心的是我们无法排除运行的应用是否是善意的. 应用直接的对硬件资源进行操作, 可能会对其他应用产生监控甚至是危害的行为.</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210709173125817.png" alt="应用对硬件资源直接调用"></p><p>因此, 操作系统需要作为应用程序与硬件资源之间的协调者, 一方面是抽象出硬件资源方便开发上层应用程序, 另一方面是完成对应用与硬件资源之间的隔离.</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210709173417683.png" alt="应用通过操作系统调用硬件资源"></p><h2 id="进程概述"><a href="#进程概述" class="headerlink" title="进程概述"></a>进程概述</h2><p>进程, 是大多数的操作系统对应用程序间隔离的实现.</p><p>每个进程作为一个<strong>隔离单元</strong>, 单独为应用提供服务. 操作系统需要对众多进程之间完成其对硬件资源需求的调度. </p><p>从操作系统的角度来看, 操作系统需要协调多个进程之间对硬件资源的需求. 操作系统采取了在电子设计中非常常用的复用手段. 在电子设计中我们常常将信号在频率和时间上分离, 使得一个信号能够被多次使用. 对操作系统来说, 采用了<strong>对时空 (即时间和空间) 上的分离</strong>, 使得进程对硬件资源在时间和空间上, 一方面得以提高<strong>资源的利用率</strong>, 另一方面也巧妙的实现了对各进程之间的<strong>隔离</strong>.</p><p>从应用程序的角度来看,  系统将应用分配到进程. 对于每个进程来说, 进程似乎能够享用所有的硬件资源. 操作系统将进程的内存空间从物理内存上划分出来, 映射出从 0 到相应大小的内存虚拟地址空间, 当进程需要访问内存中的某个地址, 系统会将虚拟地址映射回实际的物理地址进行相应的操作, 这就是操作系统对空间上的分离, 在实现上为<strong>页表 (Page tables)</strong> 的实现. </p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210710160820558.png" alt="进程虚拟地址空间"></p><p>在对于硬件资源时间分配上的分离, 也叫做分时复用. CPU讲一段时间分割为相同大小的时间片, 在一个极短的时间片上执行一个进程, 当到达了下一个时间片, 将当前进程挂起, 处理下一个进程, 看起来就像多个进程在同时执行, 也就是我们所说的<strong>并发</strong>. </p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210710161309019.png" alt="进程分时复用"></p><p>通过对进程的实现, 操作系统对各应用程序之间的隔离实现便能够完成. 当然其中会有很多细节保证进程的实现能够正常进行, 后面在细说.</p><h1 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h1><p>想要从应用程序中对相关底层资源进行调用, 首先要从应用程序跳到内核中, 由内核来完成对底层硬件资源的调用. </p><p>因此, 进程可以通过系统调用使得应用代码跳入内核中执行调用对底层资源的调用, 例如文件操作, 内存分配等等. 当应用程序需要执行这些系统调用时, 需要内核临时将应用的权限提高, 也就是之前提到的<strong>权限访问机制</strong>. </p><p>代码转化为CPU指令后分为特权指令和非特权指令, 因此在操作系统中也区分了内核态和用户态. 在特权指令的操作下能够完成对系统资源的调用, 因此需要在内核态中执行, 普通指令在用户态中执行. 当用户想要调用系统调用, 在<code>RISC-V</code>架构中需要调用<code>ecall</code>指令<sup>1</sup>, 由内核来判定该次调用是否可以执行<sup>2</sup>,如果可以执行, 则切换成内核态即跳入内核中执行相应系统调用, 完成后退回用户态. 至此这就大致是一次系统调用的过程.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* part of xv6-riscv&#x2F;user&#x2F;usys.S *&#x2F;</span><br><span class="line">#include &quot;kernel&#x2F;syscall.h&quot;</span><br><span class="line">.global fork</span><br><span class="line">fork:</span><br><span class="line"> li a7, SYS_fork</span><br><span class="line"> ecall</span><br><span class="line"> ret</span><br><span class="line">.global exit</span><br><span class="line">exit:</span><br><span class="line"> li a7, SYS_exit</span><br><span class="line"> ecall</span><br><span class="line"> ret</span><br><span class="line">.global wait</span><br><span class="line">wait:</span><br><span class="line"> li a7, SYS_wait</span><br><span class="line"> ecall</span><br><span class="line"> ret</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure><h2 id="内核架构"><a href="#内核架构" class="headerlink" title="内核架构"></a>内核架构</h2><p>由于加入了各类对相关底层资源调用的模块及系统调用, 内核也随之变得庞大起来, 因此产生了两大派别, 宏内核 (monolithic kernel) 和 微内核 (micro kernel).</p><p>宏内核的设计使得整个操作系统都能拥有完全的硬件权限, 但也因此导致了内核体积不断的增大, 且必须保证内核中的服务完全正确且能够防止应用程序的恶意破坏. 否则一旦发生错误则会导致整个内核崩溃, 操作系统崩溃只能重新启动, 对于用户来说无疑是不能接受的事情.</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210711112226058.png" alt="宏内核架构"></p><p>因此有人提出了微内核的架构设计, 即内核中只保存<code>IPC</code> (interprocess communication进程间通信), 与底层硬件交互等的底层函数, 其余文件服务, 进程管理等服务移至用户空间内作为进程实现, 保证内核的最小实现下提供服务, 减少内核崩溃的风险, 但也会导致应用操作随着进程间通信次数的增多而效率降低.</p><p><img src="https://pomelo-1305373403.cos.ap-shanghai.myqcloud.com/image-20210711112308423.png" alt="微内核架构"></p><p>两种内核架构的设计都各自有优缺点, 不同的操作系统也会由于各自的原因采取不同的设计 (也许只是设计者的喜好罢了). 并没有不好的设计, 只有不会用它的人罢了.</p><h1 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h1><ol><li>进程内部内存空间的划分及进程调度</li><li>进程在内核态和用户态之间切换的凭证</li><li>需要一点计组知识, 补两天.</li></ol><hr><p>1 :不同的CPU架构对应不同的指令集</p><p>2 : 如判定是否访问的是该进程的内存空间, 是否存在其他权限指令等. 这样做不仅保证了进程间的相互隔离, 也保证了内核自身的安全.</p>]]></content>
      
      
      <categories>
          
          <category> 计算机 </category>
          
          <category> 学习 </category>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OS学习_6.S081介绍</title>
      <link href="2021/04/23/OS%E5%AD%A6%E4%B9%A0-6-S081%E4%BB%8B%E7%BB%8D/"/>
      <url>2021/04/23/OS%E5%AD%A6%E4%B9%A0-6-S081%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction-and-Examples"><a href="#Introduction-and-Examples" class="headerlink" title="Introduction and Examples"></a>Introduction and Examples</h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol><li>理解操作系统的设计和实现. 设计是指整体的系统结构, 实现是指具体的代码设计</li><li>了解操作系统工作原理, 动手实现OS, 并通过操作系统的接口, 编写系统软件.</li></ol><h2 id="操作系统本身的目标"><a href="#操作系统本身的目标" class="headerlink" title="操作系统本身的目标"></a>操作系统本身的目标</h2><ol><li>抽象硬件. 硬件本身是较低层次的资源, 操作系统<strong>实现了高层次的接口和抽象</strong>, 像进程(Process),文件系统(file System)等, 为其他硬件提供了一个基本的环境, 也提供了更好的移植性.</li><li>其次是使得多个的应用之间能够共享计算机底层的硬件资源. 我们能够在计算机上同时运行多个应用而他们之间不会相互影响, 这叫<strong>多路复用 (multiplex)</strong>.</li><li>在多路复用下我们要保证这些程序不会相互影响, 需要<strong>隔离(Isolation)</strong>.</li><li>但是我们也需要一些有用的影响, 我们需要能够<strong>共享(Sharing)</strong>. 例如像数据交互, 进程通信等.</li><li>用户想要能够自主控制是否共享, 我们需要一个<strong>权限系统(Security / Access Control System)</strong>.</li><li>在确保操作系统自身服务正常运行的情况下, 能为应用提供<strong>高性能(Performance)</strong>, 且OS不能阻碍应用获取高的性能, 甚至需要帮助应用获得高性能.</li><li>一个操作系统需要能够<strong>满足不同用户的不同需求</strong>, 支持很多不同类型的应用. 可以打游戏, 写文档, 还能运行数据库服务.</li></ol><h2 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h2><table><thead><tr><th>应用</th><th>编译器</th><th>Shell</th><th>DB</th></tr></thead><tbody><tr><td>文件系统</td><td>进程管理</td><td>内存分配</td><td>访问控制</td></tr><tr><td>CPU</td><td>内存</td><td>硬盘</td><td>网络接口</td></tr></tbody></table><p>底层是计算机硬件. 整个计算机共用这些硬件资源</p><p>中间是内核服务, 用来管理控制计算机的资源, 同时管理用户进程, 操作系统的核心.</p><p>顶层是用户的应用.</p><p>操作系统主要研究系统的内核, 连接内核和应用之间的接口, 内核服务的架构.</p><h3 id="Kernel-API"><a href="#Kernel-API" class="headerlink" title="Kernel API"></a>Kernel API</h3><p>类似于程序的函数调用, 是向内核发起系统调用, 使得应用能够访问内核中的服务.</p><p>与函数调用不同的是, 系统调用会跳到内核中进行.</p><p>内核是在计算机启动时第一个运行的, 且始终在运行着. 内核拥有操作硬件的权限, 执行系统调用就能跳到内核中操作硬件, 而程序中的函数调用做不到这点.</p><h2 id="困难与乐趣并存"><a href="#困难与乐趣并存" class="headerlink" title="困难与乐趣并存"></a>困难与乐趣并存</h2><h3 id="矛盾点"><a href="#矛盾点" class="headerlink" title="矛盾点"></a>矛盾点</h3><p>在设计操作系统时会遇到许多矛盾点.</p><ol><li>我们希望操作系统是高效且易用的.<ul><li>高效意味着我们需要在设计上更贴近硬件底层一些</li><li>易用则需要OS为应用提供可移植的抽象接口.</li><li>需要在两者中达成一个平衡.</li></ul></li><li>而在给其他人在你的OS上开发时, 你希望能够给其他程序员更简单易用的API来调取内核服务.<ul><li>接口不能太多太复杂.</li><li>接口要有强大的功能 (我理解为很实用的, 功能齐全的)</li><li>我们需要提供出简单但是又强大的接口</li></ul></li><li>最后一个矛盾是, 想要OS能给应用更多的灵活性, 同时要保证安全性.<ul><li>应用不能跳过内核直接访问到硬件影响其他应用, 或是影响操作系统.</li></ul></li></ol><table><thead><tr><th>高效</th><th>抽象</th></tr></thead><tbody><tr><td>强大</td><td>简单</td></tr><tr><td>灵活</td><td>安全</td></tr></tbody></table><p>这是在系统设计上的三个矛盾点.</p><h3 id="交互"><a href="#交互" class="headerlink" title="交互"></a>交互</h3><p>OS提供了许多特性和大量的服务, 他们之间趋向于交互, 有时候是奇怪的交互…</p><blockquote><p>两个功能, open 和 fork</p><p>使用open打开文件, 内核会返回文件的描述符 (<code>fd</code>).</p><p>使用fork新建当前进程的副本, 内核会返回新进程的进程号(<code>pid</code>).</p><p>但是在一个进程中先open一个文件, 再fork这个进程, 新的进程能否访问到之前的<code>fd</code>呢? Yes</p><p>这就是奇怪的交互</p></blockquote><h3 id="其他的点"><a href="#其他的点" class="headerlink" title="其他的点"></a>其他的点</h3><p>OS还必须要适应硬件的飞快发展, 以及各种不同的用途</p>]]></content>
      
      
      <categories>
          
          <category> 计算机 </category>
          
          <category> 学习 </category>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识分布式事务</title>
      <link href="2021/03/22/%E5%88%9D%E8%AF%86%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>2021/03/22/%E5%88%9D%E8%AF%86%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="前置概念了解"><a href="#前置概念了解" class="headerlink" title="前置概念了解"></a>前置概念了解</h1><h2 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h2><p>事务是一组操作组成的一个操作序列, 当所有的操作都正常执行之后才能被全部提交. 只要有任意一次的操作失败了, 都将回滚所有的操作.</p><p>简单的说就是, 要么全部做完, 要么一个都别做.</p><h2 id="事务的ACID特性"><a href="#事务的ACID特性" class="headerlink" title="事务的ACID特性"></a>事务的ACID特性</h2><p>A(Atomicity)原子性</p><p>C(Consistency)一致性</p><p>I(Isolation)隔离性</p><p>D(Durability)持久性</p><h2 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h2><p>CAP是2000年在PODC上提出的一个猜想. 2002年在MIT被证明. (证明是严格的证明, 讨论了在两个互相矛盾的请求到达彼此连接不通的两个不同的分布式节点)</p><ul><li>一致性（Consistency） </li><li>可用性（Availability）</li><li>分区容错性（Partition tolerance）</li></ul><h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><p>经过了长时间的实践, 人们发现通过CAP定理来维护事物的ACID特性需要付出很大的特性, 总结出来一套弱化的事务特性. 服务化中，更多的是提升 A 以及 P，在这个过程中不可避免的会降低对 C 的要求</p><ul><li>基本可用（Basically Available）：系统能够基本运行、一直提供服务。</li><li>软状态（Soft-state）：系统不要求一直保持强一致状态。</li><li>最终一致性（Eventual consistency）：系统需要在某一时刻后达到一致性要求。</li></ul><h1 id="分布式事务产生场景"><a href="#分布式事务产生场景" class="headerlink" title="分布式事务产生场景"></a>分布式事务产生场景</h1><p>随着互联网的发展, 简单的单机提供单一服务已经不能满足当下需求. </p><p>随着大数据时代来临, 庞大的数据量单一数据库已经不能完成很好的服务.</p><p>一个业务功能可能需要跨越多个服务和操作多个数据库. 分布式事务就是为了保证不同服务器之间的数据一致性.</p><h2 id="数据库分库"><a href="#数据库分库" class="headerlink" title="数据库分库"></a>数据库分库</h2><p>一个数据对应多个数据库</p><h2 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h2><p>一个业务跨越多个服务, 同时操作多个数据库</p><h1 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h1><h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h2><p>这是最简单的分布式事务解决方案, 也是其他解决方案的<strong>基础思维</strong>.</p><p>两个角色: 协调者(TM Transaction Manager), 参与者(RM Resource Manager)</p><h3 id="投票阶段"><a href="#投票阶段" class="headerlink" title="投票阶段"></a>投票阶段</h3><p>TM通知各RM准备提交事务.</p><ul><li>如果RM可以提交事务则给TM回复确定</li><li>如果RM无法提交则回复否定</li></ul><h3 id="提交阶段"><a href="#提交阶段" class="headerlink" title="提交阶段"></a>提交阶段</h3><p>TM根据所有RM的结果决定是提交还是回滚事务.</p><ul><li>如果全部为确认响应, 发起提交请求, RM收到请求后提交事务.</li><li>如果有否定响应, 则发起回滚请求, RM收到请求后回滚事务.</li></ul><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>尽量高效的确保了数据的强一致性, 但不是100%一致.</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>TM故障: RM会一直阻塞, 事务资源被锁定, 无法继续完成事务操作和后续操作.</li><li>同步阻塞: 在等待TM回复的过程中一直占用公共资源, 导致第三方访问公共资源阻塞.</li><li>数据不一致: <ul><li>提交阶段TM发起提交请求后, 出现网络异常导致部分RM无法收到请求, 产生不一致数据.</li><li>如果协调者在第二阶段发送提交请求之后挂掉，而唯一接受到这条消息的参与者执行之后也挂掉了，即使协调者通过选举协议产生了新的协调者并通知其他参与者进行提交或回滚操作的话，都可能会与这个已经执行的参与者执行的操作不一样。</li></ul></li></ul><h2 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h2><h3 id="改动点"><a href="#改动点" class="headerlink" title="改动点"></a>改动点</h3><ol><li>引入超时机制.</li><li>新增一个阶段解决由于TM故障引起的阻塞问题.</li></ol><h3 id="第一阶段-CanCommit"><a href="#第一阶段-CanCommit" class="headerlink" title="第一阶段 CanCommit"></a>第一阶段 CanCommit</h3><p>等同于<strong>2PC</strong>的投票阶段</p><h3 id="第二阶段-PreCommit"><a href="#第二阶段-PreCommit" class="headerlink" title="第二阶段 PreCommit"></a>第二阶段 PreCommit</h3><p>TM判断各RM的响应轻快判断是否做预提交操作(PreCommit), 有两种可能:</p><ul><li><p>如果所有RM返回确认响应, 执行事务预提交</p><ol><li>向所有RM发送<code>PreCommit</code>请求</li><li>RM收到后将事务操作写入事务日志, 进行事务操作持久化.</li><li>成功完成了事务操作持久化后, 给TM确认响应, 等待下一步指令</li></ol></li><li><p>假如有RM返回了否认响应, 或者TM等待超时, 执行中断请求.</p><ol><li>TM向所有RM发送Abort请求.</li><li>RM收到Abort请求后执行事务中断.</li></ol></li></ul><h3 id="第三阶段-DoCommit"><a href="#第三阶段-DoCommit" class="headerlink" title="第三阶段 DoCommit"></a>第三阶段 DoCommit</h3><p>进行真正的事务提交</p><ul><li>执行提交<ol><li>TM收到所有RM来自PreCommit阶段的确认响应后,将状态更改为(预提交-&gt;)提交, 向所有RM发送确认提交请求.</li><li>RM收到确认提交请求后提交事务并释放事务资源.</li><li>RM完成后向TM发送确认请求.</li><li>TM收到所有RM在DoCommit阶段的确认后, 确认事务完成.</li></ol></li><li>中断事务<ol><li>TM没有收到所有RM来自PreCommit阶段的确认响应, (或是收到了RM的超时响应) (或者自身超时), 向所有的RM发送Abort请求.</li><li>RM收到Abort请求后, 根据事务操作日志中的记录回滚事务并释放事务资源.</li><li>RM完成回滚后, 向TM发送回滚完成确认响应.</li><li>TM收到RM的回滚确认后, 确认事务中断.</li></ol></li></ul><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ul><li>已经解决了<ol><li>由于TM和某些RM挂掉导致的数据一致性问题</li><li>TM单点故障问题</li></ol></li><li>但是仍然存在<ol><li>在DoCommit阶段如果TM执行事务中断, 部分RM未能收到请求默认执行事务提交而导致的数据一致性问题.</li></ol></li></ul><p>可见2PC和3PC都无法保证100%数据一致性.</p><hr><p>简单写了一些, 明日再更.</p><p>先写作业，难顶</p>]]></content>
      
      
      <categories>
          
          <category> 计算机 </category>
          
          <category> 算法 </category>
          
          <category> 分布式系统 </category>
          
          <category> 分布式事务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式事务 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
